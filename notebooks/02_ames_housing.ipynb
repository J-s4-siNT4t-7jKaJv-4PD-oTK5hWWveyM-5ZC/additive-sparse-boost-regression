{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import collections\n",
    "import warnings\n",
    "from time import perf_counter_ns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from asboostreg import SparseAdditiveBoostingRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the Ames housing dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n0      1  526301100           20        RL         141.0     31770   Pave   \n1      2  526350040           20        RH          80.0     11622   Pave   \n2      3  526351010           20        RL          81.0     14267   Pave   \n3      4  526353030           20        RL          93.0     11160   Pave   \n4      5  527105010           60        RL          74.0     13830   Pave   \n\n  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n\n  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n0        0       5    2010       WD           Normal     215000  \n1        0       6    2010       WD           Normal     105000  \n2    12500       6    2010       WD           Normal     172000  \n3        0       4    2010       WD           Normal     244000  \n4        0       3    2010       WD           Normal     189900  \n\n[5 rows x 82 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order</th>\n      <th>PID</th>\n      <th>MS SubClass</th>\n      <th>MS Zoning</th>\n      <th>Lot Frontage</th>\n      <th>Lot Area</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>Lot Shape</th>\n      <th>Land Contour</th>\n      <th>...</th>\n      <th>Pool Area</th>\n      <th>Pool QC</th>\n      <th>Fence</th>\n      <th>Misc Feature</th>\n      <th>Misc Val</th>\n      <th>Mo Sold</th>\n      <th>Yr Sold</th>\n      <th>Sale Type</th>\n      <th>Sale Condition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>526301100</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>141.0</td>\n      <td>31770</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>215000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>526350040</td>\n      <td>20</td>\n      <td>RH</td>\n      <td>80.0</td>\n      <td>11622</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>105000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>526351010</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>81.0</td>\n      <td>14267</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gar2</td>\n      <td>12500</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>172000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>526353030</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>93.0</td>\n      <td>11160</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>244000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>527105010</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>74.0</td>\n      <td>13830</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>189900</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 82 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing = pd.read_csv(\"http://dlsun.github.io/pods/data/AmesHousing.txt\", sep=\"\\t\")\n",
    "df_housing.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X = df_housing.drop(columns=[\"SalePrice\", \"PID\", \"Order\"])\n",
    "y = df_housing[\"SalePrice\"].astype(float)\n",
    "y = pd.Series((y - y.mean()) / y.std(), index=y.index)\n",
    "categorical_indices = np.array(\n",
    "    [i for i, col in enumerate(X.columns) if X[col].dtype == \"object\"]\n",
    ")\n",
    "X_numeric = X.drop(columns=X.columns[categorical_indices])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X.head()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "cv = list(kf.split(X))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "dummy = DummyRegressor()\n",
    "\n",
    "# Interpretable but not strong\n",
    "ridgereg = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False, max_categories=10),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    StandardScaler(),\n",
    "    RidgeCV(cv=cv),\n",
    ")  # Non Sparse\n",
    "treereg = make_pipeline(\n",
    "    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    DecisionTreeRegressor(max_depth=4),\n",
    ")  # Sparse\n",
    "\n",
    "# Strong but not interpretable\n",
    "rfreg = make_pipeline(\n",
    "    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    RandomForestRegressor(random_state=0),\n",
    ")  # Non Sparse\n",
    "xgbreg = xgb.XGBRegressor(random_state=0)  # Sparse\n",
    "\n",
    "# Both interpretable and strong\n",
    "ebmreg = ExplainableBoostingRegressor(interactions=0)  # Non Sparse\n",
    "sparsereg = SparseAdditiveBoostingRegressor(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=10_000,\n",
    "    l2_regularization=2.0,\n",
    "    row_subsample=0.85,\n",
    "    random_state=0,\n",
    "    n_iter_no_change=15,\n",
    "    max_bins=256,\n",
    "    min_l0_fused_regularization=0.5,\n",
    "    max_l0_fused_regularization=3.0,\n",
    "    min_samples_leaf=2,\n",
    "    validation_fraction=0.15,\n",
    ")  # Sparse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# Running fast Hyperparameter optimization for Ridge\n",
    "ridgereg.fit(X_numeric, y)\n",
    "alpha = ridgereg.named_steps[\"ridgecv\"].alpha_\n",
    "ridgereg = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False, max_categories=10),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    StandardScaler(),\n",
    "    Ridge(alpha=alpha),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, X_test, y_train, y_test, **kwargs):\n",
    "    start = perf_counter_ns()\n",
    "    model.fit(X_train, y_train, **kwargs)\n",
    "    end = perf_counter_ns()\n",
    "    elapsed = (end - start) / 1e9\n",
    "    train_error = mean_absolute_error(y_train, model.predict(X_train))\n",
    "    dummy_train_error = mean_absolute_error(\n",
    "        y_train, np.full(y_train.shape, y_train.median())\n",
    "    )\n",
    "    train_score = 1 - train_error / dummy_train_error\n",
    "    test_error = mean_absolute_error(y_test, model.predict(X_test))\n",
    "    dummy_test_error = mean_absolute_error(\n",
    "        y_test, np.full(y_test.shape, y_train.median())\n",
    "    )\n",
    "    test_score = 1 - test_error / dummy_test_error\n",
    "    name = (\n",
    "        model.__class__.__name__\n",
    "        if not isinstance(model, Pipeline)\n",
    "        else model.steps[-1][1].__class__.__name__\n",
    "    )\n",
    "    print(\n",
    "        f\"{name}: {train_score:.3f} (train), {test_score:.3f} (test), {elapsed:.3f} (s)\"\n",
    "    )\n",
    "    return test_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "------\n",
      "DummyRegressor: -0.040 (train), -0.015 (test), 0.001 (s)\n",
      "DecisionTreeRegressor: 0.556 (train), 0.387 (test), 0.132 (s)\n",
      "Ridge: 0.715 (train), 0.633 (test), 0.338 (s)\n",
      "XGBRegressor: 0.848 (train), 0.712 (test), 0.255 (s)\n",
      "RandomForestRegressor: 0.894 (train), 0.501 (test), 20.740 (s)\n",
      "ExplainableBoostingRegressor: 0.776 (train), 0.739 (test), 2.168 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.598 (train), 0.586 (test), 39.231 (s)\n",
      "\n",
      "Fold 2\n",
      "------\n",
      "DummyRegressor: -0.039 (train), -0.045 (test), 0.000 (s)\n",
      "DecisionTreeRegressor: 0.557 (train), 0.423 (test), 0.129 (s)\n",
      "Ridge: 0.714 (train), 0.624 (test), 0.351 (s)\n",
      "XGBRegressor: 0.865 (train), 0.728 (test), 0.352 (s)\n",
      "RandomForestRegressor: 0.896 (train), 0.508 (test), 20.818 (s)\n",
      "ExplainableBoostingRegressor: 0.747 (train), 0.693 (test), 1.308 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.596 (train), 0.560 (test), 17.768 (s)\n",
      "\n",
      "Fold 3\n",
      "------\n",
      "DummyRegressor: -0.039 (train), -0.049 (test), 0.001 (s)\n",
      "DecisionTreeRegressor: 0.558 (train), 0.453 (test), 0.159 (s)\n",
      "Ridge: 0.716 (train), 0.634 (test), 0.315 (s)\n",
      "XGBRegressor: 0.899 (train), 0.675 (test), 0.308 (s)\n",
      "RandomForestRegressor: 0.897 (train), 0.541 (test), 20.630 (s)\n",
      "ExplainableBoostingRegressor: 0.755 (train), 0.718 (test), 2.146 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.105 (train), 0.102 (test), 12.507 (s)\n",
      "\n",
      "Fold 4\n",
      "------\n",
      "DummyRegressor: -0.039 (train), -0.035 (test), 0.000 (s)\n",
      "DecisionTreeRegressor: 0.554 (train), 0.414 (test), 0.167 (s)\n",
      "Ridge: 0.712 (train), 0.658 (test), 0.324 (s)\n",
      "XGBRegressor: 0.911 (train), 0.720 (test), 0.389 (s)\n",
      "RandomForestRegressor: 0.895 (train), 0.540 (test), 20.774 (s)\n",
      "ExplainableBoostingRegressor: 0.762 (train), 0.724 (test), 2.494 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.593 (train), 0.586 (test), 12.501 (s)\n",
      "\n",
      "Fold 5\n",
      "------\n",
      "DummyRegressor: -0.040 (train), -0.046 (test), 0.001 (s)\n",
      "DecisionTreeRegressor: 0.544 (train), 0.424 (test), 0.172 (s)\n",
      "Ridge: 0.714 (train), 0.627 (test), 0.328 (s)\n",
      "XGBRegressor: 0.866 (train), 0.714 (test), 0.256 (s)\n",
      "RandomForestRegressor: 0.897 (train), 0.525 (test), 20.826 (s)\n",
      "ExplainableBoostingRegressor: 0.763 (train), 0.726 (test), 1.805 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.633 (train), 0.613 (test), 6.846 (s)\n",
      "\n",
      "Fold 6\n",
      "------\n",
      "DummyRegressor: -0.039 (train), -0.047 (test), 0.001 (s)\n",
      "DecisionTreeRegressor: 0.547 (train), 0.422 (test), 0.156 (s)\n",
      "Ridge: 0.718 (train), 0.625 (test), 0.304 (s)\n",
      "XGBRegressor: 0.855 (train), 0.718 (test), 0.290 (s)\n",
      "RandomForestRegressor: 0.895 (train), 0.535 (test), 20.616 (s)\n",
      "ExplainableBoostingRegressor: 0.771 (train), 0.719 (test), 4.826 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.546 (train), 0.521 (test), 5.238 (s)\n",
      "\n",
      "Fold 7\n",
      "------\n",
      "DummyRegressor: -0.040 (train), -0.017 (test), 0.001 (s)\n",
      "DecisionTreeRegressor: 0.562 (train), 0.393 (test), 0.153 (s)\n",
      "Ridge: 0.717 (train), 0.596 (test), 0.306 (s)\n",
      "XGBRegressor: 0.868 (train), 0.697 (test), 0.373 (s)\n",
      "RandomForestRegressor: 0.898 (train), 0.528 (test), 17.083 (s)\n",
      "ExplainableBoostingRegressor: 0.768 (train), 0.688 (test), 2.500 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.529 (train), 0.504 (test), 4.869 (s)\n",
      "\n",
      "Fold 8\n",
      "------\n",
      "DummyRegressor: -0.041 (train), -0.036 (test), 0.001 (s)\n",
      "DecisionTreeRegressor: 0.541 (train), 0.439 (test), 0.149 (s)\n",
      "Ridge: 0.715 (train), 0.656 (test), 0.324 (s)\n",
      "XGBRegressor: 0.866 (train), 0.720 (test), 0.286 (s)\n",
      "RandomForestRegressor: 0.895 (train), 0.556 (test), 20.115 (s)\n",
      "ExplainableBoostingRegressor: 0.768 (train), 0.727 (test), 1.886 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.513 (train), 0.513 (test), 2.196 (s)\n",
      "\n",
      "Fold 9\n",
      "------\n",
      "DummyRegressor: -0.041 (train), -0.053 (test), 0.000 (s)\n",
      "DecisionTreeRegressor: 0.546 (train), 0.482 (test), 0.170 (s)\n",
      "Ridge: 0.713 (train), 0.649 (test), 0.351 (s)\n",
      "XGBRegressor: 0.844 (train), 0.728 (test), 0.303 (s)\n",
      "RandomForestRegressor: 0.895 (train), 0.574 (test), 20.697 (s)\n",
      "ExplainableBoostingRegressor: 0.769 (train), 0.731 (test), 2.333 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.500 (train), 0.529 (test), 2.155 (s)\n",
      "\n",
      "Fold 10\n",
      "------\n",
      "DummyRegressor: -0.037 (train), -0.054 (test), 0.001 (s)\n",
      "DecisionTreeRegressor: 0.553 (train), 0.424 (test), 0.157 (s)\n",
      "Ridge: 0.715 (train), 0.642 (test), 0.322 (s)\n",
      "XGBRegressor: 0.858 (train), 0.714 (test), 0.275 (s)\n",
      "RandomForestRegressor: 0.895 (train), 0.514 (test), 20.975 (s)\n",
      "ExplainableBoostingRegressor: 0.781 (train), 0.712 (test), 2.262 (s)\n",
      "SparseAdditiveBoostingRegressor: 0.099 (train), 0.079 (test), 1.528 (s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_scores = collections.defaultdict(list)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv, 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"Fold {i}\")\n",
    "    print(\"------\")\n",
    "\n",
    "    test = evaluate(dummy, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Dummy\"].append(test)\n",
    "\n",
    "    test = evaluate(treereg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Decision Tree\"].append(test)\n",
    "\n",
    "    test = evaluate(ridgereg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Elastic Net\"].append(test)\n",
    "\n",
    "    X_train_numeric, X_test_numeric = (\n",
    "        X_numeric.iloc[train_index],\n",
    "        X_numeric.iloc[test_index],\n",
    "    )\n",
    "\n",
    "    test = evaluate(\n",
    "        xgbreg,\n",
    "        X_train_numeric,\n",
    "        X_test_numeric,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        eval_set=[(X_test_numeric, y_test)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=False,\n",
    "    )\n",
    "    test_scores[\"XGBoost\"].append(test)\n",
    "\n",
    "    test = evaluate(rfreg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Random Forest\"].append(test)\n",
    "\n",
    "    test = evaluate(ebmreg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"EBM\"].append(test)\n",
    "\n",
    "    test = evaluate(\n",
    "        sparsereg,\n",
    "        X_train_numeric,\n",
    "        X_test_numeric,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        validation_set=(X_test_numeric, y_test),\n",
    "    )\n",
    "    test_scores[\"SparseReg\"].append(test)\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_df = pd.DataFrame(test_scores)\n",
    "test_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(test_scores_df.drop(\"Dummy\", axis=1).round(3).to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
