{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import collections\n",
    "import warnings\n",
    "from time import perf_counter_ns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from asboostreg import SparseAdditiveBoostingRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the Ames housing dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n0      1  526301100           20        RL         141.0     31770   Pave   \n1      2  526350040           20        RH          80.0     11622   Pave   \n2      3  526351010           20        RL          81.0     14267   Pave   \n3      4  526353030           20        RL          93.0     11160   Pave   \n4      5  527105010           60        RL          74.0     13830   Pave   \n\n  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n\n  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n0        0       5    2010       WD           Normal     215000  \n1        0       6    2010       WD           Normal     105000  \n2    12500       6    2010       WD           Normal     172000  \n3        0       4    2010       WD           Normal     244000  \n4        0       3    2010       WD           Normal     189900  \n\n[5 rows x 82 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order</th>\n      <th>PID</th>\n      <th>MS SubClass</th>\n      <th>MS Zoning</th>\n      <th>Lot Frontage</th>\n      <th>Lot Area</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>Lot Shape</th>\n      <th>Land Contour</th>\n      <th>...</th>\n      <th>Pool Area</th>\n      <th>Pool QC</th>\n      <th>Fence</th>\n      <th>Misc Feature</th>\n      <th>Misc Val</th>\n      <th>Mo Sold</th>\n      <th>Yr Sold</th>\n      <th>Sale Type</th>\n      <th>Sale Condition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>526301100</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>141.0</td>\n      <td>31770</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>215000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>526350040</td>\n      <td>20</td>\n      <td>RH</td>\n      <td>80.0</td>\n      <td>11622</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>105000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>526351010</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>81.0</td>\n      <td>14267</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gar2</td>\n      <td>12500</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>172000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>526353030</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>93.0</td>\n      <td>11160</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>244000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>527105010</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>74.0</td>\n      <td>13830</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>189900</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 82 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n0      1  526301100           20        RL         141.0     31770   Pave   \n1      2  526350040           20        RH          80.0     11622   Pave   \n2      3  526351010           20        RL          81.0     14267   Pave   \n3      4  526353030           20        RL          93.0     11160   Pave   \n4      5  527105010           60        RL          74.0     13830   Pave   \n\n  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n\n  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n0        0       5    2010       WD           Normal     215000  \n1        0       6    2010       WD           Normal     105000  \n2    12500       6    2010       WD           Normal     172000  \n3        0       4    2010       WD           Normal     244000  \n4        0       3    2010       WD           Normal     189900  \n\n[5 rows x 82 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Order</th>\n      <th>PID</th>\n      <th>MS SubClass</th>\n      <th>MS Zoning</th>\n      <th>Lot Frontage</th>\n      <th>Lot Area</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>Lot Shape</th>\n      <th>Land Contour</th>\n      <th>...</th>\n      <th>Pool Area</th>\n      <th>Pool QC</th>\n      <th>Fence</th>\n      <th>Misc Feature</th>\n      <th>Misc Val</th>\n      <th>Mo Sold</th>\n      <th>Yr Sold</th>\n      <th>Sale Type</th>\n      <th>Sale Condition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>526301100</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>141.0</td>\n      <td>31770</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>215000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>526350040</td>\n      <td>20</td>\n      <td>RH</td>\n      <td>80.0</td>\n      <td>11622</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>105000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>526351010</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>81.0</td>\n      <td>14267</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gar2</td>\n      <td>12500</td>\n      <td>6</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>172000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>526353030</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>93.0</td>\n      <td>11160</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>244000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>527105010</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>74.0</td>\n      <td>13830</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>189900</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 82 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing = pd.read_csv(\"http://dlsun.github.io/pods/data/AmesHousing.txt\", sep=\"\\t\")\n",
    "df_housing.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X = df_housing.drop(columns=[\"SalePrice\", \"PID\", \"Order\"])\n",
    "y = df_housing[\"SalePrice\"].astype(float)\n",
    "y = pd.Series((y - y.mean()) / y.std(), index=y.index)\n",
    "categorical_indices = np.array(\n",
    "    [i for i, col in enumerate(X.columns) if X[col].dtype == \"object\"]\n",
    ")\n",
    "X_numeric = X.drop(columns=X.columns[categorical_indices])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "X.head()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "cv = list(kf.split(X))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "dummy = DummyRegressor()\n",
    "\n",
    "# Interpretable but not strong\n",
    "ridgereg = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False, max_categories=10),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    StandardScaler(),\n",
    "    RidgeCV(cv=cv),\n",
    ")  # Non Sparse\n",
    "treereg = make_pipeline(\n",
    "    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    DecisionTreeRegressor(max_depth=4),\n",
    ")  # Sparse\n",
    "\n",
    "# Strong but not interpretable\n",
    "rfreg = make_pipeline(\n",
    "    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    RandomForestRegressor(random_state=0),\n",
    ")  # Non Sparse\n",
    "xgbreg = xgb.XGBRegressor(random_state=0)  # Sparse\n",
    "\n",
    "# Both interpretable and strong\n",
    "ebmreg = ExplainableBoostingRegressor(interactions=0)  # Non Sparse\n",
    "sparsereg = SparseAdditiveBoostingRegressor(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=10_000,\n",
    "    l2_regularization=2.0,\n",
    "    max_depth=6,\n",
    "    row_subsample=0.632,\n",
    "    random_state=0,\n",
    "    n_iter_no_change=10,\n",
    "    max_bins=100,\n",
    ")  # Sparse"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Comparing the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Running fast Hyperparameter optimization for Ridge\n",
    "ridgereg.fit(X_numeric, y)\n",
    "alpha = ridgereg.named_steps[\"ridgecv\"].alpha_\n",
    "ridgereg = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False, max_categories=10),\n",
    "    SimpleImputer(add_indicator=True),\n",
    "    StandardScaler(),\n",
    "    Ridge(alpha=alpha),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, X_test, y_train, y_test, **kwargs):\n",
    "    start = perf_counter_ns()\n",
    "    model.fit(X_train, y_train, **kwargs)\n",
    "    end = perf_counter_ns()\n",
    "    elapsed = (end - start) / 1e9\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    name = (\n",
    "        model.__class__.__name__\n",
    "        if not isinstance(model, Pipeline)\n",
    "        else model.steps[-1][1].__class__.__name__\n",
    "    )\n",
    "    print(\n",
    "        f\"{name}: {train_score:.3f} (train), {test_score:.3f} (test), {elapsed:.3f} (s)\"\n",
    "    )\n",
    "    return test_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "------\n",
      "DummyRegressor: 0.000 (train), -0.003 (test), 0.000 (s)\n",
      "DecisionTreeRegressor: 0.812 (train), 0.554 (test), 0.084 (s)\n",
      "Ridge: 0.919 (train), 0.812 (test), 0.230 (s)\n",
      "XGBRegressor: 0.980 (train), 0.885 (test), 0.373 (s)\n",
      "RandomForestRegressor: 0.984 (train), 0.612 (test), 8.444 (s)\n",
      "ExplainableBoostingRegressor: 0.950 (train), 0.851 (test), 1.971 (s)\n",
      "SparseAdditiveBoostingRegressor: -0.291 (train), -0.314 (test), 0.276 (s)\n",
      "\n",
      "Fold 2\n",
      "------\n",
      "DummyRegressor: 0.000 (train), -0.000 (test), 0.000 (s)\n",
      "DecisionTreeRegressor: 0.808 (train), 0.633 (test), 0.139 (s)\n",
      "Ridge: 0.915 (train), 0.845 (test), 0.310 (s)\n",
      "XGBRegressor: 0.984 (train), 0.922 (test), 0.264 (s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 36\u001b[0m\n\u001b[0;32m     24\u001b[0m test \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[0;32m     25\u001b[0m     xgbreg,\n\u001b[0;32m     26\u001b[0m     X_train_numeric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m )\n\u001b[0;32m     34\u001b[0m test_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test)\n\u001b[1;32m---> 36\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m test_scores[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(test)\n\u001b[0;32m     39\u001b[0m test \u001b[38;5;241m=\u001b[39m evaluate(ebmreg, X_train, X_test, y_train, y_test)\n",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, X_train, X_test, y_train, y_test, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(model, X_train, X_test, y_train, y_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      2\u001b[0m     start \u001b[38;5;241m=\u001b[39m perf_counter_ns()\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     end \u001b[38;5;241m=\u001b[39m perf_counter_ns()\n\u001b[0;32m      5\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m (end \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1e9\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\PycharmProjects\\additive-sparse-boost-regression\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_scores = collections.defaultdict(list)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv, 1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    print(f\"Fold {i}\")\n",
    "    print(\"------\")\n",
    "\n",
    "    test = evaluate(dummy, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Dummy\"].append(test)\n",
    "\n",
    "    test = evaluate(treereg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Decision Tree\"].append(test)\n",
    "\n",
    "    test = evaluate(ridgereg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Elastic Net\"].append(test)\n",
    "\n",
    "    X_train_numeric, X_test_numeric = (\n",
    "        X_numeric.iloc[train_index],\n",
    "        X_numeric.iloc[test_index],\n",
    "    )\n",
    "\n",
    "    test = evaluate(\n",
    "        xgbreg,\n",
    "        X_train_numeric,\n",
    "        X_test_numeric,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        eval_set=[(X_test_numeric, y_test)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=False,\n",
    "    )\n",
    "    test_scores[\"XGBoost\"].append(test)\n",
    "\n",
    "    test = evaluate(rfreg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"Random Forest\"].append(test)\n",
    "\n",
    "    test = evaluate(ebmreg, X_train, X_test, y_train, y_test)\n",
    "    test_scores[\"EBM\"].append(test)\n",
    "\n",
    "    test = evaluate(\n",
    "        sparsereg,\n",
    "        X_train_numeric,\n",
    "        X_test_numeric,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        validation_set=(X_test_numeric, y_test),\n",
    "    )\n",
    "    test_scores[\"SparseReg\"].append(test)\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "      Dummy  Decision Tree  Elastic Net   XGBoost  Random Forest       EBM  \\\n0 -0.003407       0.553888     0.811892  0.884842       0.611996  0.851345   \n1 -0.000092       0.632983     0.845110  0.921871       0.649268  0.861835   \n2 -0.000387       0.543707     0.844391  0.834974       0.570932  0.880538   \n3 -0.000486       0.642401     0.893536  0.917660       0.692364  0.925785   \n4 -0.000353       0.649737     0.866149  0.908873       0.650828  0.913224   \n5 -0.000084       0.659418     0.845634  0.913533       0.674692  0.912196   \n6 -0.003682       0.540593     0.752622  0.847567       0.619382  0.819932   \n7 -0.001526       0.697793     0.874272  0.916567       0.722162  0.927635   \n8 -0.006774       0.708505     0.872922  0.922240       0.726452  0.917330   \n9 -0.000190       0.674228     0.873821  0.901770       0.661492  0.893796   \n\n   SparseReg  \n0   0.602910  \n1   0.635699  \n2  -0.396731  \n3   0.604775  \n4   0.463032  \n5   0.546811  \n6   0.567193  \n7   0.598072  \n8   0.629276  \n9  -0.160902  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Dummy</th>\n      <th>Decision Tree</th>\n      <th>Elastic Net</th>\n      <th>XGBoost</th>\n      <th>Random Forest</th>\n      <th>EBM</th>\n      <th>SparseReg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.003407</td>\n      <td>0.553888</td>\n      <td>0.811892</td>\n      <td>0.884842</td>\n      <td>0.611996</td>\n      <td>0.851345</td>\n      <td>0.602910</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.000092</td>\n      <td>0.632983</td>\n      <td>0.845110</td>\n      <td>0.921871</td>\n      <td>0.649268</td>\n      <td>0.861835</td>\n      <td>0.635699</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.000387</td>\n      <td>0.543707</td>\n      <td>0.844391</td>\n      <td>0.834974</td>\n      <td>0.570932</td>\n      <td>0.880538</td>\n      <td>-0.396731</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.000486</td>\n      <td>0.642401</td>\n      <td>0.893536</td>\n      <td>0.917660</td>\n      <td>0.692364</td>\n      <td>0.925785</td>\n      <td>0.604775</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.000353</td>\n      <td>0.649737</td>\n      <td>0.866149</td>\n      <td>0.908873</td>\n      <td>0.650828</td>\n      <td>0.913224</td>\n      <td>0.463032</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.000084</td>\n      <td>0.659418</td>\n      <td>0.845634</td>\n      <td>0.913533</td>\n      <td>0.674692</td>\n      <td>0.912196</td>\n      <td>0.546811</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-0.003682</td>\n      <td>0.540593</td>\n      <td>0.752622</td>\n      <td>0.847567</td>\n      <td>0.619382</td>\n      <td>0.819932</td>\n      <td>0.567193</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.001526</td>\n      <td>0.697793</td>\n      <td>0.874272</td>\n      <td>0.916567</td>\n      <td>0.722162</td>\n      <td>0.927635</td>\n      <td>0.598072</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.006774</td>\n      <td>0.708505</td>\n      <td>0.872922</td>\n      <td>0.922240</td>\n      <td>0.726452</td>\n      <td>0.917330</td>\n      <td>0.629276</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>-0.000190</td>\n      <td>0.674228</td>\n      <td>0.873821</td>\n      <td>0.901770</td>\n      <td>0.661492</td>\n      <td>0.893796</td>\n      <td>-0.160902</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_df = pd.DataFrame(test_scores)\n",
    "test_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      " & Decision Tree & Elastic Net & XGBoost & Random Forest & EBM & SparseReg \\\\\n",
      "\\midrule\n",
      "0 & 0.554000 & 0.812000 & 0.885000 & 0.612000 & 0.851000 & 0.603000 \\\\\n",
      "1 & 0.633000 & 0.845000 & 0.922000 & 0.649000 & 0.862000 & 0.636000 \\\\\n",
      "2 & 0.544000 & 0.844000 & 0.835000 & 0.571000 & 0.881000 & -0.397000 \\\\\n",
      "3 & 0.642000 & 0.894000 & 0.918000 & 0.692000 & 0.926000 & 0.605000 \\\\\n",
      "4 & 0.650000 & 0.866000 & 0.909000 & 0.651000 & 0.913000 & 0.463000 \\\\\n",
      "5 & 0.659000 & 0.846000 & 0.914000 & 0.675000 & 0.912000 & 0.547000 \\\\\n",
      "6 & 0.541000 & 0.753000 & 0.848000 & 0.619000 & 0.820000 & 0.567000 \\\\\n",
      "7 & 0.698000 & 0.874000 & 0.917000 & 0.722000 & 0.928000 & 0.598000 \\\\\n",
      "8 & 0.709000 & 0.873000 & 0.922000 & 0.726000 & 0.917000 & 0.629000 \\\\\n",
      "9 & 0.674000 & 0.874000 & 0.902000 & 0.661000 & 0.894000 & -0.161000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(test_scores_df.drop(\"Dummy\", axis=1).round(3).to_latex())"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
